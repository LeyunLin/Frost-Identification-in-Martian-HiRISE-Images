{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frost Identification in Martian HiRISE Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embark on an independent research endeavor aimed at developing a robust classifier for distinguishing images of Martian terrain with frost. Leveraging Keras and Python, this project explores the dataset accessible at NASA's JPL Dataverse, specifically curated to study Mars' seasonal frost cycle and its impact on climate and surface evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import json\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is structured with images (in png format) and corresponding labels (in json files), organized into \"subframes.\" Each subframe is a 5120x5120 pixel image, a crop of the original HiRISE images. These subframes have been further sliced into 299x299 \"tiles,\" each annotated with labels ('frost' or 'background') for ML algorithms. The dataset consists of 214 subframes and a total of 119,920 tiles. Annotation information is stored in JSON files provided by human annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging configuration\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    format='%(asctime)s | %(levelname)-5s | %(module)-15s | %(message)s')\n",
    "\n",
    "IMAGE_SIZE = (299, 299)  # All images contained in this dataset are 299x299 (originally, to match Inception v3 input size)\n",
    "SEED = 17\n",
    "\n",
    "# Head directory containing all image subframes. Update with the relative path of your data directory\n",
    "data_head_dir = Path('./data')\n",
    "\n",
    "# Find all subframe directories\n",
    "subdirs = [Path(subdir.stem) for subdir in data_head_dir.iterdir() if subdir.is_dir()]\n",
    "src_image_ids = ['_'.join(a_path.name.split('_')[:3]) for a_path in subdirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train/val/test subframe IDs\n",
    "def load_text_ids(file_path):\n",
    "    \"\"\"Simple helper to load all lines from a text file\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = [line.strip() for line in f.readlines()]\n",
    "    return lines\n",
    "\n",
    "# Load the subframe names for the three data subsets\n",
    "train_ids = load_text_ids('./train_source_images.txt')\n",
    "validate_ids = load_text_ids('./val_source_images.txt')\n",
    "test_ids = load_text_ids('./test_source_images.txt')\n",
    "\n",
    "# Generate a list containing the dataset split for the matching subdirectory names\n",
    "subdir_splits = []\n",
    "for src_id in src_image_ids:\n",
    "    if src_id in train_ids:\n",
    "        subdir_splits.append('train')\n",
    "    elif src_id in validate_ids:\n",
    "        subdir_splits.append('validate')\n",
    "    elif(src_id in test_ids):\n",
    "        subdir_splits.append('test')\n",
    "    else:\n",
    "        logging.warning(f'{src_id}: Did not find designated split in train/validate/test list.')\n",
    "        subdir_splits.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Data Exploration and Pre-processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image tiles are categorized into 'background' and 'frost' classes for binary classification, with individual tiles serving as data points for the final project.\n",
    "Files for data splitting into train, test, and validation are available. However, an improved version of these files will be provided upon repository creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:47:18 | INFO  | utils           | NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from PIL import Image \n",
    "\n",
    "def load_and_preprocess(img_loc, label):\n",
    "    def _inner_function(img_loc, label):\n",
    "        # Convert tensor to native type\n",
    "        img_loc_str = img_loc.numpy().decode('utf-8')\n",
    "        \n",
    "        # Load image using PIL and convert to RGB\n",
    "        img = Image.open(img_loc_str).convert('RGB')\n",
    "        \n",
    "        # Convert PIL image to numpy array\n",
    "        img = np.array(img)\n",
    "        img = tf.image.resize(img, [299, 299])\n",
    "        \n",
    "        # Normalize the image to the [0, 1] range\n",
    "        img = img / 255.0\n",
    "\n",
    "        # Convert label to integer (assuming binary classification)\n",
    "        label = 1 if label.numpy().decode('utf-8') == 'frost' else 0\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    # Wrap the Python function\n",
    "    X, y = tf.py_function(_inner_function, [img_loc, label], [tf.float32, tf.int64])\n",
    "    \n",
    "    # Set the shape of the tensors\n",
    "    X.set_shape([299, 299, 3])\n",
    "    y.set_shape([])  # Scalar label\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_subdir_data(dir_path, image_size, seed=None):\n",
    "    \n",
    "    \"\"\"Helper to create a TF dataset from each image subdirectory\"\"\"\n",
    "    \n",
    "    # Grab only the classes that (1) we want to keep and (2) exist in this directory\n",
    "    tile_dir = dir_path / Path('tiles')\n",
    "    label_dir = dir_path /Path('labels')\n",
    "    \n",
    "    loc_list = []\n",
    "    \n",
    "    for folder in os.listdir(tile_dir):\n",
    "        if os.path.isdir(os.path.join(tile_dir, folder)):\n",
    "            for file in os.listdir(os.path.join(tile_dir, folder)):\n",
    "                if file.endswith(\".png\"):\n",
    "                    loc_list.append((os.path.join(os.path.join(tile_dir, folder), file), folder))\n",
    "\n",
    "    return loc_list\n",
    "\n",
    "# Loop over all subframes, loading each into a list\n",
    "tf_data_train, tf_data_test, tf_data_val = [], [], []\n",
    "tf_dataset_train, tf_dataset_test, tf_dataset_val = [], [], []\n",
    "\n",
    "# Update the batch and buffer size as per your model requirements\n",
    "buffer_size = 64\n",
    "batch_size = 32\n",
    "\n",
    "for subdir, split in zip(subdirs, subdir_splits):\n",
    "    full_path = data_head_dir / subdir\n",
    "    if split=='validate':\n",
    "        tf_data_val.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
    "    elif split=='train':\n",
    "        tf_data_train.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
    "    elif split=='test':\n",
    "        tf_data_test.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
    "        \n",
    "random.shuffle(tf_data_train)\n",
    "img_list, label_list = zip(*tf_data_train)\n",
    "img_list_t = tf.convert_to_tensor(img_list)\n",
    "lb_list_t = tf.convert_to_tensor(label_list)\n",
    "\n",
    "tf_dataset_train = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
    "tf_dataset_train = tf_dataset_train.map(load_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "tf_dataset_train = tf_dataset_train.shuffle(buffer_size=buffer_size).batch(batch_size) \n",
    "\n",
    "random.shuffle(tf_data_val)\n",
    "img_list, label_list = zip(*tf_data_val)\n",
    "img_list_t = tf.convert_to_tensor(img_list)\n",
    "lb_list_t = tf.convert_to_tensor(label_list)\n",
    "\n",
    "tf_dataset_val = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
    "tf_dataset_val = tf_dataset_val.map(load_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "tf_dataset_val = tf_dataset_val.shuffle(buffer_size=buffer_size).batch(batch_size) \n",
    "\n",
    "random.shuffle(tf_data_test)\n",
    "img_list, label_list = zip(*tf_data_test)\n",
    "img_list_t = tf.convert_to_tensor(img_list)\n",
    "lb_list_t = tf.convert_to_tensor(label_list)\n",
    "\n",
    "tf_dataset_test = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
    "tf_dataset_test = tf_dataset_test.map(load_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "tf_dataset_test = tf_dataset_test.shuffle(buffer_size=buffer_size).batch(batch_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c). Training CNN + MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement empirical regularization techniques, including cropping, random zooming, rotation, flipping, contrast adjustments, and translation for image augmentation, utilizing tools such as OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "def augment_batch(batch_images):\n",
    "    processed_images = []\n",
    "\n",
    "    for img in batch_images.numpy():\n",
    "        if np.random.rand() > 0.5:\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "        angle = np.random.randint(-30, 30)  \n",
    "        h, w = img.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1)\n",
    "        img = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "        min_zoom_factor = 0.8\n",
    "        max_zoom_factor = 1.2\n",
    "        zoom_factor = np.random.uniform(min_zoom_factor, max_zoom_factor)\n",
    "        h, w = img.shape[:2]\n",
    "        new_h = int(h * zoom_factor)\n",
    "        new_w = int(w * zoom_factor)\n",
    "        img = cv2.resize(img, (new_w, new_h))\n",
    "\n",
    "        start_x = max(0, (new_w - w) // 2)\n",
    "        start_y = max(0, (new_h - h) // 2)\n",
    "        img = img[start_y:start_y + h, start_x:start_x + w]\n",
    "\n",
    "        contrast_factor = 1.0 + np.random.uniform(-0.5, 0.5) \n",
    "        img = np.clip(contrast_factor * img, 0, 255).astype(np.uint8)\n",
    "\n",
    "        tx, ty = np.random.randint(-30, 30), np.random.randint(-30, 30) \n",
    "        translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "        img = cv2.warpAffine(img, translation_matrix, (w, h))\n",
    "\n",
    "        processed_images.append(img)\n",
    "\n",
    "    return np.stack(processed_images, axis=0)\n",
    "\n",
    "def apply_augmentation_to_batch(images, labels):\n",
    "    processed_images = tf.py_function(augment_batch, [images], tf.uint8)\n",
    "    processed_images.set_shape([None, 299, 299, 3])  \n",
    "    return processed_images, labels\n",
    "tf_dataset_train_augmented = tf_dataset_train.map(apply_augmentation_to_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a three-layer CNN followed by a dense layer, allowing flexibility in choosing kernel sizes, layer depths, and the number of neurons in the dense layer (MLP). Incorporate ReLU activation functions, softmax function, batch normalization, a dropout rate of 30%, L2 regularization, and the ADAM optimizer. Employ cross-entropy loss and conduct training for a minimum of 20 epochs with early stopping using the validation set. Save the network parameters with the lowest validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "928/928 [==============================] - 1686s 2s/step - loss: 1.2850 - accuracy: 0.5611 - val_loss: 3.0357 - val_accuracy: 0.3218\n",
      "Epoch 2/20\n",
      "928/928 [==============================] - 1560s 2s/step - loss: 1.1130 - accuracy: 0.5797 - val_loss: 2.7178 - val_accuracy: 0.3184\n",
      "Epoch 3/20\n",
      "928/928 [==============================] - 1608s 2s/step - loss: 1.0454 - accuracy: 0.5863 - val_loss: 5.3819 - val_accuracy: 0.3218\n",
      "Epoch 4/20\n",
      "928/928 [==============================] - 2271s 2s/step - loss: 1.0094 - accuracy: 0.5887 - val_loss: 6.1318 - val_accuracy: 0.3218\n",
      "Epoch 5/20\n",
      "928/928 [==============================] - 4905s 5s/step - loss: 0.9760 - accuracy: 0.5887 - val_loss: 3.3406 - val_accuracy: 0.3218\n",
      "Epoch 6/20\n",
      "928/928 [==============================] - 5960s 6s/step - loss: 0.9496 - accuracy: 0.5943 - val_loss: 3.1880 - val_accuracy: 0.3218\n",
      "Epoch 7/20\n",
      "928/928 [==============================] - 5716s 6s/step - loss: 0.9153 - accuracy: 0.6035 - val_loss: 5.3343 - val_accuracy: 0.3218\n",
      "Epoch 8/20\n",
      "928/928 [==============================] - 3604s 4s/step - loss: 0.8968 - accuracy: 0.6020 - val_loss: 3.3226 - val_accuracy: 0.3218\n",
      "Epoch 9/20\n",
      "928/928 [==============================] - 2889s 3s/step - loss: 0.8706 - accuracy: 0.5988 - val_loss: 2.4476 - val_accuracy: 0.3218\n",
      "Epoch 10/20\n",
      "928/928 [==============================] - 2802s 3s/step - loss: 0.8535 - accuracy: 0.6041 - val_loss: 5.6028 - val_accuracy: 0.3218\n",
      "Epoch 11/20\n",
      "928/928 [==============================] - 2714s 3s/step - loss: 0.8305 - accuracy: 0.6084 - val_loss: 4.3966 - val_accuracy: 0.3218\n",
      "Epoch 12/20\n",
      "928/928 [==============================] - 2721s 3s/step - loss: 0.8095 - accuracy: 0.6106 - val_loss: 3.0992 - val_accuracy: 0.3218\n",
      "Epoch 13/20\n",
      "928/928 [==============================] - 2663s 3s/step - loss: 0.8044 - accuracy: 0.6081 - val_loss: 2.0755 - val_accuracy: 0.3218\n",
      "Epoch 14/20\n",
      "928/928 [==============================] - 2688s 3s/step - loss: 0.7784 - accuracy: 0.6176 - val_loss: 3.0797 - val_accuracy: 0.3218\n",
      "Epoch 15/20\n",
      "928/928 [==============================] - 2830s 3s/step - loss: 0.7711 - accuracy: 0.6135 - val_loss: 2.8394 - val_accuracy: 0.3218\n",
      "Epoch 16/20\n",
      "928/928 [==============================] - 2696s 3s/step - loss: 0.7645 - accuracy: 0.6118 - val_loss: 2.6381 - val_accuracy: 0.3218\n",
      "Epoch 17/20\n",
      "344/928 [==========>...................] - ETA: 25:24 - loss: 0.7602 - accuracy: 0.6125"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "from tensorflow.keras.regularizers import l2 \n",
    "from tensorflow.keras import models  # Add this import statement\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Layer\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_regularizer=l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Second Convolutional Layer\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Third Convolutional Layer\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Flatten Layer\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # Dense Layer (MLP)\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output Layer\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "input_shape = (299, 299, 3)  \n",
    "num_classes = 2 \n",
    "learning_rate = 0.0001\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(tf_dataset_train_augmented, epochs=epochs, validation_data=tf_dataset_val, callbacks=[early_stopping])\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report Precision, Recall, and F1 score for the developed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 124s 281ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.78      0.48      4932\n",
      "           1       0.66      0.23      0.34      9187\n",
      "\n",
      "    accuracy                           0.42     14119\n",
      "   macro avg       0.50      0.50      0.41     14119\n",
      "weighted avg       0.55      0.42      0.39     14119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_predictions = model.predict(tf_dataset_test)\n",
    "test_predictions_labels = np.argmax(test_predictions, axis=1) \n",
    "test_labels = np.concatenate([y.numpy() for _, y in tf_dataset_test])\n",
    "report = classification_report(test_labels, test_predictions_labels)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
